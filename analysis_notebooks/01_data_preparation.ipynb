{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ACC Survival Analysis: Define Track A/B Cohorts\n",
    "\n",
    "**Goal**: Define paper-mirroring (Track A) and sensitivity (Track B) cohorts with proper exclusions\n",
    "\n",
    "**Endpoints**:\n",
    "- **OS (Overall Survival)**: Death from any cause\n",
    "- **CSS (Cancer-Specific Survival)**: Death attributable to ACC\n",
    "\n",
    "**Track Definitions**:\n",
    "- **Track A (Paper-mirroring)**: Exclude missing TNM staging (for baseline TNM-only comparison)\n",
    "- **Track B (Sensitivity)**: Keep all cases, encode missing TNM as \"Unknown\"\n",
    "\n",
    "**Split**: 2:1 train:validation (67%:33%), stratified by event status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Load Raw SEER Data\n",
    "\n",
    "We reload the raw data to extract CSS endpoint information that wasn't included in notebook 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../ACC数据/r分析seer/SEER纯ACC数据.xlsx\n",
      "\n",
      "Raw data shape: (2833, 52)\n",
      "Total records: 2833\n"
     ]
    }
   ],
   "source": [
    "# Load raw SEER data\n",
    "raw_data_path = Path(\"../ACC数据/r分析seer/SEER纯ACC数据.xlsx\")\n",
    "print(f\"Loading: {raw_data_path}\")\n",
    "\n",
    "df_raw = pd.read_excel(raw_data_path)\n",
    "\n",
    "print(f\"\\nRaw data shape: {df_raw.shape}\")\n",
    "print(f\"Total records: {len(df_raw)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER cause-specific death classification values:\n",
      "SEER cause-specific death classification\n",
      "Alive or dead of other cause             1893\n",
      "Dead (attributable to this cancer dx)     909\n",
      "Dead (missing/unknown COD)                 31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "\n",
      "SEER other cause of death classification values:\n",
      "SEER other cause of death classification\n",
      "Alive or dead due to cancer                                2261\n",
      "Dead (attributable to causes other than this cancer dx)     541\n",
      "Dead (missing/unknown COD)                                   31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check cause-of-death columns for CSS endpoint\n",
    "print(\"SEER cause-specific death classification values:\")\n",
    "print(df_raw[\"SEER cause-specific death classification\"].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nSEER other cause of death classification values:\")\n",
    "print(df_raw[\"SEER other cause of death classification\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Extract All Required Variables Including CSS Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "def recode_site_to_4_categories(site_value):\n    \"\"\"\n    Recode ICD-O-3 site codes to 4 consolidated categories.\n    \"\"\"\n    if pd.isna(site_value):\n        return np.nan\n\n    site_str = str(site_value)\n    code = site_str.split(\"-\")[0] if \"-\" in site_str else site_str\n    code_prefix = code[:3] if len(code) >= 3 else code\n\n    # Major salivary glands\n    if code_prefix in [\"C07\", \"C08\"]:\n        return \"大唾液腺\"\n    # Larynx and hypopharynx\n    if code_prefix in [\"C32\", \"C12\", \"C13\"]:\n        return \"喉和下咽\"\n    # Nasal cavity/sinuses/nasopharynx\n    if code_prefix in [\"C30\", \"C31\", \"C11\"]:\n        return \"鼻腔鼻窦副鼻窦鼻咽\"\n    # Oral/oropharynx/other\n    return \"口腔口咽其它\"\n\n\n# Column mapping including CSS endpoint and T/N/M components\ncolumn_mapping = {\n    \"ID\": \"编号\",\n    \"age\": \"年龄\",\n    \"sex\": \"性别\",\n    \"site_raw\": \"原发部位\",\n    \"grade\": \"分化级别(thru 2017)\",\n    \"radiotherapy\": \"放疗\",\n    \"chemotherapy\": \"化疗\",\n    \"tumor_number\": \"肿瘤数量\",\n    \"race\": \"种族\",\n    \"marital_status\": \"婚姻\",\n    \"urban_rural\": \"城乡\",\n    \"time_os\": \"存活月数\",\n    \"event_os\": \"生存（截止至研究日期）\",\n    \"TNMstage\": \"TNM\",\n    \"T\": \"T\",\n    \"N\": \"N\",\n    \"M\": \"M\",\n    \"css_classification\": \"SEER cause-specific death classification\",\n}\n\n# Select and rename columns\ndf = df_raw[[v for v in column_mapping.values()]].copy()\ndf.columns = list(column_mapping.keys())\n\n# Apply site recoding\ndf[\"site\"] = df[\"site_raw\"].apply(recode_site_to_4_categories)\ndf = df.drop(columns=[\"site_raw\"])\n\nprint(f\"Selected {len(df.columns)} variables\")\nprint(f\"Data shape: {df.shape}\")\n\n# Show T, N, M distributions\nprint(\"\\nT, N, M component distributions:\")\nfor col in [\"T\", \"N\", \"M\"]:\n    print(f\"\\n{col}:\")\n    print(df[col].value_counts())"
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Define CSS Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSS endpoint definition:\n",
      "  Cancer-specific deaths (event_css=1): 909\n",
      "  Censored (event_css=0): 1924\n",
      "  CSS event rate: 32.1%\n",
      "\n",
      "OS endpoint:\n",
      "  Deaths (event_os=1): 1481\n",
      "  Alive (event_os=0): 1352\n",
      "  OS event rate: 52.3%\n"
     ]
    }
   ],
   "source": [
    "# Define CSS event based on SEER cause-specific death classification\n",
    "# \"Dead (attributable to this cancer dx)\" = cancer-specific death (event_css = 1)\n",
    "# \"Alive or dead of other cause\" = censored for CSS (event_css = 0)\n",
    "\n",
    "df[\"event_css\"] = (\n",
    "    df[\"css_classification\"] == \"Dead (attributable to this cancer dx)\"\n",
    ").astype(int)\n",
    "\n",
    "# CSS uses same time as OS (time from diagnosis to death or last follow-up)\n",
    "df[\"time_css\"] = df[\"time_os\"]\n",
    "\n",
    "print(\"CSS endpoint definition:\")\n",
    "print(f\"  Cancer-specific deaths (event_css=1): {df['event_css'].sum()}\")\n",
    "print(f\"  Censored (event_css=0): {(df['event_css']==0).sum()}\")\n",
    "print(f\"  CSS event rate: {df['event_css'].mean()*100:.1f}%\")\n",
    "\n",
    "print(\"\\nOS endpoint:\")\n",
    "print(f\"  Deaths (event_os=1): {df['event_os'].sum()}\")\n",
    "print(f\"  Alive (event_os=0): {(df['event_os']==0).sum()}\")\n",
    "print(f\"  OS event rate: {df['event_os'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final columns:\n",
      "['ID', 'age', 'sex', 'grade', 'radiotherapy', 'chemotherapy', 'tumor_number', 'race', 'marital_status', 'urban_rural', 'time_os', 'event_os', 'TNMstage', 'site', 'event_css', 'time_css']\n"
     ]
    }
   ],
   "source": [
    "# Drop intermediate column\n",
    "df = df.drop(columns=[\"css_classification\"])\n",
    "\n",
    "# Rename for clarity\n",
    "# time_os and time_css are identical (time from diagnosis)\n",
    "# event_os: 1=death (any cause), 0=alive\n",
    "# event_css: 1=cancer-specific death, 0=alive or other cause death\n",
    "\n",
    "print(\"Final columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# Define candidate variables for Cox screening\n# TNMstage = combined stage, T/N/M = separate components\ncandidate_vars = [\n    \"age\",\n    \"sex\",\n    \"site\",\n    \"grade\",\n    \"radiotherapy\",\n    \"chemotherapy\",\n    \"tumor_number\",\n    \"race\",\n    \"marital_status\",\n    \"urban_rural\",\n    \"TNMstage\",\n    \"T\",\n    \"N\",\n    \"M\",\n]\n\n# Convert categorical variables\nfor var in candidate_vars:\n    df[var] = df[var].astype(\"category\")\n\n# Convert numeric outcome variables\ndf[\"event_os\"] = pd.to_numeric(df[\"event_os\"], errors=\"coerce\").astype(int)\ndf[\"event_css\"] = df[\"event_css\"].astype(int)\ndf[\"time_os\"] = pd.to_numeric(df[\"time_os\"], errors=\"coerce\")\ndf[\"time_css\"] = df[\"time_css\"].astype(float)\n\nprint(\"Data type conversion complete\")\nprint(f\"\\nDataset shape: {df.shape}\")\nprint(f\"\\nCandidate variables: {len(candidate_vars)}\")\nprint(\"  Non-staging: age, sex, site, grade, radiotherapy, chemotherapy, tumor_number, race, marital_status, urban_rural\")\nprint(\"  Staging (combined): TNMstage\")\nprint(\"  Staging (separate): T, N, M\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Apply Exclusion Criteria (Common to Both Tracks)\n",
    "\n",
    "Exclusions applied to all cohorts:\n",
    "1. Missing or invalid survival time (time <= 0 or NaN)\n",
    "2. Missing survival status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying common exclusion criteria...\n",
      "\n",
      "Starting N: 2833\n",
      "  Excluded for invalid/missing time: 33\n",
      "  Excluded for missing status: 0\n",
      "\n",
      "After common exclusions: 2800 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying common exclusion criteria...\")\n",
    "print(f\"\\nStarting N: {len(df)}\")\n",
    "\n",
    "# Exclusion 1: Missing or invalid survival time\n",
    "valid_time = (df[\"time_os\"].notna()) & (df[\"time_os\"] > 0)\n",
    "n_invalid_time = (~valid_time).sum()\n",
    "print(f\"  Excluded for invalid/missing time: {n_invalid_time}\")\n",
    "\n",
    "# Exclusion 2: Missing survival status\n",
    "valid_status = df[\"event_os\"].notna()\n",
    "n_invalid_status = (~valid_status).sum()\n",
    "print(f\"  Excluded for missing status: {n_invalid_status}\")\n",
    "\n",
    "# Apply common exclusions\n",
    "df_clean = df[valid_time & valid_status].copy()\n",
    "print(f\"\\nAfter common exclusions: {len(df_clean)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Define Track A Cohort (Paper-Mirroring)\n",
    "\n",
    "**Track A**: Exclude cases with missing TNM staging\n",
    "- This allows baseline TNM-only model comparison (as in the reference paper)\n",
    "- Primary analysis cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Track A cohort (paper-mirroring)...\n",
      "\n",
      "Starting N (after common exclusions): 2800\n",
      "  Records with missing TNMstage: 1306\n",
      "  Records with 'UNK Stage': 111\n",
      "\n",
      "Track A cohort: 1383 records\n",
      "  OS events: 573 (41.4%)\n",
      "  CSS events: 385 (27.8%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Track A cohort (paper-mirroring)...\")\n",
    "print(f\"\\nStarting N (after common exclusions): {len(df_clean)}\")\n",
    "\n",
    "# Check TNM availability\n",
    "tnm_valid = df_clean[\"TNMstage\"].notna()\n",
    "n_missing_tnm = (~tnm_valid).sum()\n",
    "print(f\"  Records with missing TNMstage: {n_missing_tnm}\")\n",
    "\n",
    "# Also exclude \"UNK Stage\" as it's essentially missing\n",
    "tnm_known = tnm_valid & (df_clean[\"TNMstage\"] != \"UNK Stage\")\n",
    "n_unk_stage = (df_clean[\"TNMstage\"] == \"UNK Stage\").sum()\n",
    "print(f\"  Records with 'UNK Stage': {n_unk_stage}\")\n",
    "\n",
    "# Create Track A\n",
    "df_trackA = df_clean[tnm_known].copy()\n",
    "print(f\"\\nTrack A cohort: {len(df_trackA)} records\")\n",
    "print(\n",
    "    f\"  OS events: {df_trackA['event_os'].sum()} ({df_trackA['event_os'].mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  CSS events: {df_trackA['event_css'].sum()} ({df_trackA['event_css'].mean()*100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track A TNMstage distribution:\n",
      "TNMstage\n",
      "1            346\n",
      "4A           272\n",
      "2            270\n",
      "3            227\n",
      "4C           139\n",
      "4B           118\n",
      "4NOS           7\n",
      "4              4\n",
      "UNK Stage      0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Track A: TNMstage distribution\n",
    "print(\"Track A TNMstage distribution:\")\n",
    "print(df_trackA[\"TNMstage\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Define Track B Cohort (Sensitivity Analysis)\n",
    "\n",
    "**Track B**: Keep all cases, encode missing TNM as \"Unknown\"\n",
    "- This maximizes sample size for ACC (where staging is often missing)\n",
    "- Sensitivity analysis cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Track B cohort (sensitivity)...\n",
      "\n",
      "Starting N (after common exclusions): 2800\n",
      "\n",
      "Track B cohort: 2800 records\n",
      "  OS events: 1467 (52.4%)\n",
      "  CSS events: 908 (32.4%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Track B cohort (sensitivity)...\")\n",
    "print(f\"\\nStarting N (after common exclusions): {len(df_clean)}\")\n",
    "\n",
    "# Create Track B (all records, encode missing TNM)\n",
    "df_trackB = df_clean.copy()\n",
    "\n",
    "# Encode missing TNM and \"UNK Stage\" as \"Unknown\"\n",
    "# First, convert to string to handle the category\n",
    "df_trackB[\"TNMstage\"] = df_trackB[\"TNMstage\"].astype(str)\n",
    "df_trackB.loc[df_trackB[\"TNMstage\"].isin([\"nan\", \"UNK Stage\"]), \"TNMstage\"] = \"Unknown\"\n",
    "df_trackB[\"TNMstage\"] = df_trackB[\"TNMstage\"].astype(\"category\")\n",
    "\n",
    "print(f\"\\nTrack B cohort: {len(df_trackB)} records\")\n",
    "print(\n",
    "    f\"  OS events: {df_trackB['event_os'].sum()} ({df_trackB['event_os'].mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  CSS events: {df_trackB['event_css'].sum()} ({df_trackB['event_css'].mean()*100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track B TNMstage distribution:\n",
      "TNMstage\n",
      "Unknown    1417\n",
      "1           346\n",
      "4A          272\n",
      "2           270\n",
      "3           227\n",
      "4C          139\n",
      "4B          118\n",
      "4NOS          7\n",
      "4             4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Track B: TNMstage distribution (including Unknown)\n",
    "print(\"Track B TNMstage distribution:\")\n",
    "print(df_trackB[\"TNMstage\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 9. Create Train/Validation Splits (2:1)\n",
    "\n",
    "For each track, create:\n",
    "- Training set (67%): For model development\n",
    "- Validation set (33%): For internal validation\n",
    "\n",
    "Split is stratified by OS event status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Track A Split:\n",
      "  Training: 926 (67.0%)\n",
      "  Validation: 457 (33.0%)\n",
      "  Train OS events: 384 (41.5%)\n",
      "  Val OS events: 189 (41.4%)\n",
      "\n",
      "Track B Split:\n",
      "  Training: 1876 (67.0%)\n",
      "  Validation: 924 (33.0%)\n",
      "  Train OS events: 983 (52.4%)\n",
      "  Val OS events: 484 (52.4%)\n"
     ]
    }
   ],
   "source": [
    "def create_train_val_split(df, track_name, random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Create 2:1 train/validation split, stratified by OS event status.\n",
    "    \"\"\"\n",
    "    train, val = train_test_split(\n",
    "        df, test_size=0.33, random_state=random_state, stratify=df[\"event_os\"]\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{track_name} Split:\")\n",
    "    print(f\"  Training: {len(train)} ({len(train)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Validation: {len(val)} ({len(val)/len(df)*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"  Train OS events: {train['event_os'].sum()} ({train['event_os'].mean()*100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Val OS events: {val['event_os'].sum()} ({val['event_os'].mean()*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    return train, val\n",
    "\n",
    "\n",
    "# Track A splits\n",
    "trackA_train, trackA_val = create_train_val_split(df_trackA, \"Track A\")\n",
    "\n",
    "# Track B splits\n",
    "trackB_train, trackB_val = create_train_val_split(df_trackB, \"Track B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 10. Align Categorical Levels\n",
    "\n",
    "Ensure validation sets use the same category levels as training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track A categorical levels aligned\n",
      "Track B categorical levels aligned\n"
     ]
    }
   ],
   "source": [
    "def align_categorical_levels(train_df, val_df, full_df, candidate_vars):\n",
    "    \"\"\"\n",
    "    Align categorical levels between train/val/full datasets.\n",
    "    Uses training set categories as reference.\n",
    "    \"\"\"\n",
    "    for var in candidate_vars:\n",
    "        if var in train_df.columns:\n",
    "            train_categories = train_df[var].cat.categories\n",
    "            val_df[var] = pd.Categorical(\n",
    "                val_df[var],\n",
    "                categories=train_categories,\n",
    "                ordered=train_df[var].cat.ordered,\n",
    "            )\n",
    "            full_df[var] = pd.Categorical(\n",
    "                full_df[var],\n",
    "                categories=train_categories,\n",
    "                ordered=train_df[var].cat.ordered,\n",
    "            )\n",
    "    return train_df, val_df, full_df\n",
    "\n",
    "\n",
    "# Align Track A\n",
    "trackA_train, trackA_val, df_trackA = align_categorical_levels(\n",
    "    trackA_train, trackA_val, df_trackA, candidate_vars\n",
    ")\n",
    "print(\"Track A categorical levels aligned\")\n",
    "\n",
    "# Align Track B\n",
    "trackB_train, trackB_val, df_trackB = align_categorical_levels(\n",
    "    trackB_train, trackB_val, df_trackB, candidate_vars\n",
    ")\n",
    "print(\"Track B categorical levels aligned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 11. Summary: Cohort Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COHORT FLOW SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Raw SEER data: 2833 records\n",
      "After common exclusions (valid time & status): 2800 records\n",
      "  - Excluded for invalid time: 33\n",
      "  - Excluded for missing status: 0\n",
      "\n",
      "--- Track A (Paper-mirroring, excludes missing TNM) ---\n",
      "  Full cohort: 1383 records\n",
      "  Training: 926 records\n",
      "  Validation: 457 records\n",
      "  OS events: 573 (41.4%)\n",
      "  CSS events: 385 (27.8%)\n",
      "\n",
      "--- Track B (Sensitivity, includes Unknown TNM) ---\n",
      "  Full cohort: 2800 records\n",
      "  Training: 1876 records\n",
      "  Validation: 924 records\n",
      "  OS events: 1467 (52.4%)\n",
      "  CSS events: 908 (32.4%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"COHORT FLOW SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nRaw SEER data: {len(df_raw)} records\")\n",
    "print(f\"After common exclusions (valid time & status): {len(df_clean)} records\")\n",
    "print(f\"  - Excluded for invalid time: {n_invalid_time}\")\n",
    "print(f\"  - Excluded for missing status: {n_invalid_status}\")\n",
    "\n",
    "print(f\"\\n--- Track A (Paper-mirroring, excludes missing TNM) ---\")\n",
    "print(f\"  Full cohort: {len(df_trackA)} records\")\n",
    "print(f\"  Training: {len(trackA_train)} records\")\n",
    "print(f\"  Validation: {len(trackA_val)} records\")\n",
    "print(\n",
    "    f\"  OS events: {df_trackA['event_os'].sum()} ({df_trackA['event_os'].mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  CSS events: {df_trackA['event_css'].sum()} ({df_trackA['event_css'].mean()*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Track B (Sensitivity, includes Unknown TNM) ---\")\n",
    "print(f\"  Full cohort: {len(df_trackB)} records\")\n",
    "print(f\"  Training: {len(trackB_train)} records\")\n",
    "print(f\"  Validation: {len(trackB_val)} records\")\n",
    "print(\n",
    "    f\"  OS events: {df_trackB['event_os'].sum()} ({df_trackB['event_os'].mean()*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"  CSS events: {df_trackB['event_css'].sum()} ({df_trackB['event_css'].mean()*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 12. Save All Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort files saved:\n",
      "  trackA_full.csv\n",
      "  trackA_full.pkl\n",
      "  trackA_train.csv\n",
      "  trackA_train.pkl\n",
      "  trackA_val.csv\n",
      "  trackA_val.pkl\n",
      "  trackB_full.csv\n",
      "  trackB_full.pkl\n",
      "  trackB_train.csv\n",
      "  trackB_train.pkl\n",
      "  trackB_val.csv\n",
      "  trackB_val.pkl\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "output_dir = Path(\"../data/processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save Track A cohorts\n",
    "trackA_train.to_pickle(output_dir / \"trackA_train.pkl\")\n",
    "trackA_val.to_pickle(output_dir / \"trackA_val.pkl\")\n",
    "df_trackA.to_pickle(output_dir / \"trackA_full.pkl\")\n",
    "\n",
    "trackA_train.to_csv(output_dir / \"trackA_train.csv\", index=False)\n",
    "trackA_val.to_csv(output_dir / \"trackA_val.csv\", index=False)\n",
    "df_trackA.to_csv(output_dir / \"trackA_full.csv\", index=False)\n",
    "\n",
    "# Save Track B cohorts\n",
    "trackB_train.to_pickle(output_dir / \"trackB_train.pkl\")\n",
    "trackB_val.to_pickle(output_dir / \"trackB_val.pkl\")\n",
    "df_trackB.to_pickle(output_dir / \"trackB_full.pkl\")\n",
    "\n",
    "trackB_train.to_csv(output_dir / \"trackB_train.csv\", index=False)\n",
    "trackB_val.to_csv(output_dir / \"trackB_val.csv\", index=False)\n",
    "df_trackB.to_csv(output_dir / \"trackB_full.csv\", index=False)\n",
    "\n",
    "print(\"Cohort files saved:\")\n",
    "for f in sorted(output_dir.glob(\"track*\")):\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data dictionary updated: ../data/processed/data_dictionary.json\n"
     ]
    }
   ],
   "source": [
    "# Update data dictionary\n",
    "data_dict_path = output_dir / \"data_dictionary.json\"\n",
    "\n",
    "# Load existing or create new\n",
    "if data_dict_path.exists():\n",
    "    with open(data_dict_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_dict = json.load(f)\n",
    "else:\n",
    "    data_dict = {}\n",
    "\n",
    "# Add cohort information\n",
    "data_dict.update(\n",
    "    {\n",
    "        \"cohort_definition_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"endpoints\": {\n",
    "            \"OS\": {\n",
    "                \"time_var\": \"time_os\",\n",
    "                \"event_var\": \"event_os\",\n",
    "                \"description\": \"Overall survival (death from any cause)\",\n",
    "            },\n",
    "            \"CSS\": {\n",
    "                \"time_var\": \"time_css\",\n",
    "                \"event_var\": \"event_css\",\n",
    "                \"description\": \"Cancer-specific survival (death attributable to ACC)\",\n",
    "            },\n",
    "        },\n",
    "        \"track_A\": {\n",
    "            \"description\": \"Paper-mirroring analysis - excludes missing TNM staging\",\n",
    "            \"exclusion_criteria\": [\n",
    "                \"Missing or invalid survival time (time <= 0)\",\n",
    "                \"Missing survival status\",\n",
    "                \"Missing TNM stage\",\n",
    "                \"TNM stage = 'UNK Stage'\",\n",
    "            ],\n",
    "            \"full_n\": len(df_trackA),\n",
    "            \"train_n\": len(trackA_train),\n",
    "            \"val_n\": len(trackA_val),\n",
    "            \"os_events\": int(df_trackA[\"event_os\"].sum()),\n",
    "            \"css_events\": int(df_trackA[\"event_css\"].sum()),\n",
    "        },\n",
    "        \"track_B\": {\n",
    "            \"description\": \"Sensitivity analysis - includes all cases, missing TNM encoded as 'Unknown'\",\n",
    "            \"exclusion_criteria\": [\n",
    "                \"Missing or invalid survival time (time <= 0)\",\n",
    "                \"Missing survival status\",\n",
    "            ],\n",
    "            \"full_n\": len(df_trackB),\n",
    "            \"train_n\": len(trackB_train),\n",
    "            \"val_n\": len(trackB_val),\n",
    "            \"os_events\": int(df_trackB[\"event_os\"].sum()),\n",
    "            \"css_events\": int(df_trackB[\"event_css\"].sum()),\n",
    "        },\n",
    "        \"split_method\": \"2:1 train:validation (67%:33%), stratified by OS event status\",\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"candidate_variables\": candidate_vars,\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(data_dict_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nData dictionary updated: {data_dict_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Cohorts Created:\n",
    "\n",
    "| Track | Description | Full | Train | Validation |\n",
    "|-------|-------------|------|-------|------------|\n",
    "| A | Paper-mirroring (excludes missing TNM) | See output above | 67% | 33% |\n",
    "| B | Sensitivity (includes Unknown TNM) | See output above | 67% | 33% |\n",
    "\n",
    "### Endpoints:\n",
    "- **OS (Overall Survival)**: `time_os`, `event_os` (1=death any cause, 0=alive)\n",
    "- **CSS (Cancer-Specific Survival)**: `time_css`, `event_css` (1=ACC death, 0=censored)\n",
    "\n",
    "### Next Steps:\n",
    "1. **Notebook 03**: Univariate Cox screening (p < 0.05 selection)\n",
    "2. **Notebook 04**: Forward-stepwise multivariate Cox\n",
    "3. **Notebook 05/06**: Nomogram construction (OS/CSS)\n",
    "4. **Notebook 07/08**: Internal and external validation\n",
    "\n",
    "### Files Saved:\n",
    "- `trackA_train.pkl`, `trackA_val.pkl`, `trackA_full.pkl` (+ CSV versions)\n",
    "- `trackB_train.pkl`, `trackB_val.pkl`, `trackB_full.pkl` (+ CSV versions)\n",
    "- Updated `data_dictionary.json`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acc-survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}